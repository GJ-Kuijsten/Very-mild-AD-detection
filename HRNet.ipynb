{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95d31a4a-f0d2-4f46-bfef-8ceaaed4223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torch in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: nibabel in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (5.3.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\gjkku\\appdata\\roaming\\python\\python312\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: timm in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (1.0.15)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from nibabel) (24.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from timm) (0.29.3)\n",
      "Requirement already satisfied: safetensors in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (4.66.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gjkku\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas torch torchvision nibabel opencv-python timm scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cae19a3-c281-45ce-89a0-785ec5f2ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HRNet\n",
    "\n",
    "# loading all libraries used\n",
    "import pandas as pd # for handling tabular data\n",
    "import os # for interacting with file system\n",
    "import torch # PyTorch library\n",
    "from torch.utils.data import Dataset, DataLoader # for dataset and batching\n",
    "from torchvision import transforms # for applying image transformation (data augmentation)\n",
    "from PIL import Image # for image loading and applying the transforms\n",
    "import numpy as np # for numerical operations\n",
    "import nibabel as nib # For loading medical imaging files (.hdr and .img files)\n",
    "from sklearn.model_selection import train_test_split # for splitting the data into train and test set\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc # metrics used for evaluation of the model\n",
    "import matplotlib.pyplot as plt # for plotting and visualisations\n",
    "import cv2 # for image processing\n",
    "import timm # For loading the pretrained model\n",
    "import torch.nn as nn # layers of the Neural Network\n",
    "import torch.optim as optim # using the AdamW optimizer and the scheduler\n",
    "import time # To measure training time\n",
    "import csv # to write metrics into a csv file\n",
    "from torchvision.transforms.functional import gaussian_blur # additional transform to add blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc3341bd-4453-43fd-9392-7bebd92d3c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'M/F', 'Hand', 'Age', 'Educ', 'SES', 'MMSE', 'CDR', 'eTIV',\n",
      "       'nWBV', 'ASF', 'Delay', 'Class', 'MRI_Path'],\n",
      "      dtype='object')\n",
      "   CDR  label\n",
      "0  0.0      0\n",
      "1  0.0      0\n",
      "2  0.5      1\n",
      "8  0.0      0\n",
      "9  0.0      0\n",
      "label\n",
      "0    135\n",
      "1     70\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# loading csv file with all paths to the MRI files and subject information\n",
    "df = pd.read_csv(r\"C:\\Users\\gjkku\\OneDrive\\Documenten\\CSAI year 3\\Thesis\\csv_binary\\binary_with_mri_paths.csv\", sep='\\t')\n",
    "\n",
    "# columns of the csv file to understand the structure of the dataset\n",
    "print(df.columns)\n",
    "\n",
    "# using only subjects that are non-demented (CDR 0) and very mild demented (CDR 0.5) \n",
    "df = df[df['CDR'].isin([0.0, 0.5])].dropna(subset=['CDR'])\n",
    "\n",
    "# converting to binary labels: CDR 0 = 0 and CDR 0.5 = 1\n",
    "df['label'] = df['CDR'].apply(lambda x: 0 if x == 0.0 else 1)\n",
    "\n",
    "# printing the first 5 subjects with CDR 0 or CDR 0.5 and the count of each class to check\n",
    "print(df[['CDR', 'label']].head())\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1599873-2422-4a81-ac48-c320bcbb0045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    135\n",
      "1    135\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# dataset is imbalanced -> oversampling the minority class (CDR 0.5 / label 1) to match the majority class (CDR 0/ label 0)\n",
    "df_class_0 = df[df['label'] == 0]\n",
    "df_class_1 = df[df['label'] == 1].sample(n=135, replace=True, random_state=42)\n",
    "\n",
    "# combining both classes and shuffle the dataset\n",
    "balanced_df = pd.concat([df_class_0, df_class_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#printing class counts to check if dataset is balanced\n",
    "print(balanced_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a31dc496-00d9-49d8-a841-917cbbf73fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set class distribution:\n",
      "label\n",
      "0    108\n",
      "1    108\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation set class distribution:\n",
      "label\n",
      "0    27\n",
      "1    27\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# dataset split into 80% train/20% validation\n",
    "train_set, validation_set = train_test_split(balanced_df, test_size=0.2, stratify=balanced_df['label'], random_state=42) # stratify -> equal numbers of each class\n",
    "\n",
    "# distribution of the train dataset\n",
    "print(\"Train set class distribution:\")\n",
    "print(train_set['label'].value_counts())\n",
    "\n",
    "# distribution of the validation dataset\n",
    "print(\"\\nValidation set class distribution:\")\n",
    "print(validation_set['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9893027f-1a12-4687-81d1-3e8b30a686fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load and preprocess MRI files (.img/.hdr files)\n",
    "def MRI_slicing(img_path, target_size=(224, 224), axis_slice=1):\n",
    "    # loading .img/.hdr file (NiBabel finds the img and then automatically finds the .hdr file that belongs to it)\n",
    "    img = nib.load(img_path)\n",
    "    data = img.get_fdata()\n",
    "    \n",
    "    # normalizing the image using z-score normalization -> formula = (X - mean)/ std.dev\n",
    "    data = (data - np.mean(data)) / np.std(data)\n",
    "    \n",
    "    # getting the coronal slice of the 3D MRI image (axis_slice: sagittal = 0, coronal = 1, axial = 2)\n",
    "    middle_slice = data.shape[axis_slice] // 2\n",
    "    if axis_slice == 0: \n",
    "        image_slice = data[middle_slice, :, :]\n",
    "    elif axis_slice == 1:\n",
    "        image_slice = data[:, middle_slice, :]\n",
    "    else:\n",
    "        image_slice = data[:, :, middle_slice]\n",
    "    \n",
    "    # resizing image to (224, 224) using OpenCV\n",
    "    image_slice = cv2.resize(image_slice, target_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # normalizing pixel values between the range [0, 1]\n",
    "    image_slice = (image_slice - np.min(image_slice)) / (np.max(image_slice) - np.min(image_slice))\n",
    "\n",
    "    # returns the 2D image slice as a float32 array\n",
    "    return image_slice.astype(np.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c58b247-454f-4ffd-9dbf-1344ab3a68f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing a PyTorch dataset for loading images and labels\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, axis_slice=1):\n",
    "        # initialize with a dataframe, transforms, and the axis for slicing\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.axis_slice = axis_slice\n",
    "    \n",
    "    def __len__(self):\n",
    "        # returns the number of samples in the dataset\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # getting the i-th sample: image path + label\n",
    "        row = self.data.iloc[i]\n",
    "        img_path = row['MRI_Path']  \n",
    "        label = int(row['label'])\n",
    "\n",
    "        # using the slicing function to load and preprocess the image\n",
    "        image_slice = MRI_slicing(img_path, axis_slice=self.axis_slice)\n",
    "\n",
    "        # convert the grayscale images to RGB, else the pretrained models can't use it\n",
    "        image_slice = np.stack([image_slice]*3, axis=-1)  # (H, W, 3)\n",
    "\n",
    "        # applying transforms/data augmentation (transforms are getting defined in a later cell)\n",
    "        if self.transform:\n",
    "            image_slice = self.transform(Image.fromarray((image_slice * 255).astype(np.uint8)))\n",
    "            \n",
    "        # returning an image tensor with the assigned label\n",
    "        return image_slice, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88733248-8aab-4ab9-bfd3-0803ecfac03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "\n",
    "# transform for training using flipping, rotating, affine, color jitter, normalizing\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomAffine(degrees=5, translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "])\n",
    "\n",
    "# transform that uses noise for training (This is used after epoch 10 as defined in the training loop)\n",
    "transform_with_noise = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomAffine(degrees=5, translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "    # data augmentation for testing robustness\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.5)), # gaussian blur\n",
    "    transforms.Lambda(lambda x: x + 0.01 * torch.randn_like(x)) # random noise\n",
    "])\n",
    "\n",
    "# validation transform using only normalizing (no noise for validation set)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "236c0795-f513-4c79-b452-c4248b5ad4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the PyTorch dataset for training and validation\n",
    "train_dataset = MRIDataset(train_set, transform=transform)\n",
    "val_dataset = MRIDataset(validation_set, transform=val_transform) # -> no noise for the validation set\n",
    "\n",
    "# using the PyTorch dataloader to create batches and shuffling the batch\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "148dfe0c-9abd-4029-a8e6-f33f6f46b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# laoding pretrained HRNet w18 for binary classification with timm library\n",
    "model = timm.create_model(\"hrnet_w18\", pretrained=True, num_classes=2)\n",
    "\n",
    "# freeze early layers (stage 1) to prevent overfitting\n",
    "for name, param in model.named_parameters():\n",
    "    if 'stage1' in name:\n",
    "        param_requires_grad = False\n",
    "\n",
    "# modifying classifier head with dropout for regularization\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5), # dropout regulation -> randomly selected neurons are ignored during training -> helps generalizing\n",
    "    nn.Linear(model.classifier.in_features, 2)\n",
    ")\n",
    "\n",
    "# moving model to specified device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24dbd4dd-ae54-4212-b82b-f0e03b44864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss -> cross-entropy loss with label smoothing for binary classification\n",
    "loss_function = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# optimizer -> AdamW with learning rate and weight decay\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# learning rate scheduler: ReduceLROnPlateau\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff13dc09-e737-4bec-bb02-d43a888dbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train and evaluate the model\n",
    "def train(model, train_loader, validation_loader, loss_function, optimizer, scheduler, device, epochs=50):\n",
    "    \n",
    "    # keeping track of the best model to save it\n",
    "    best_val_accuracy = 0\n",
    "    \n",
    "    # training loop\n",
    "    for epoch in range(epochs):\n",
    "        # using noisy training data after epoch 10 \n",
    "        if epoch == 10:\n",
    "            print(\"Noisy training data is now being used\")\n",
    "            train_dataset.transform = transform_with_noise\n",
    "            \n",
    "        # training mode keeping track of total loss over each epoch and calculating accuracy for each epoch\n",
    "        model.train()\n",
    "        loss_over_epoch = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        # iterate over training batches\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # forward pass, computing loss, backpropagation to compute gradients and updating the weights of the model\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            # tracking loss and accuracy\n",
    "            loss_over_epoch += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        # computing train accuracy \n",
    "        train_accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss_over_epoch:.4f} - Train accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "        \n",
    "        # evaluation mode\n",
    "        model.eval()\n",
    "        val_correct, val_total = 0, 0\n",
    "\n",
    "        # lists to store all predictions, true labels, and probabilities for computing metrics of the validation set\n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        # iterate over validation batches (without gradient computation)\n",
    "        with torch.no_grad():\n",
    "            for images, labels in validation_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                # raw logits of the model \n",
    "                outputs = model(images)\n",
    "\n",
    "                # computing probabilities for class 1 (CDR 0.5) using softmax and predictions using argmax\n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1] # -> probability of class 1 (CDR 0.5)\n",
    "                preds = torch.argmax(outputs, dim=1) \n",
    "\n",
    "                # storing the predictions, true labels, and probabilities into the lists\n",
    "                predictions.extend(preds.cpu().numpy())\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "                probabilities.extend(probs.cpu().numpy())\n",
    "                \n",
    "                \n",
    "        # metrics (accuracy, precision, recall, F1-score, AUC)\n",
    "        validation_accuracy = 100 * (np.array(predictions) == np.array(true_labels)).sum() / len(true_labels)\n",
    "        precision = precision_score(true_labels, predictions)\n",
    "        recall = recall_score(true_labels, predictions)\n",
    "        f1 = f1_score(true_labels, predictions)\n",
    "        auc = roc_auc_score(true_labels, probabilities)\n",
    "\n",
    "        # saving the best model if it improved the validation accuracy\n",
    "        if validation_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = validation_accuracy\n",
    "            torch.save(model.state_dict(), 'HRNet_best_model.pth')\n",
    "            print(\"The best model is saved\")\n",
    "\n",
    "        # printing metrics of each epoch\n",
    "        print(f\"Validation Accuracy: {validation_accuracy:.2f}%\")\n",
    "        print(f\"Precision: {precision:.2f} | Recall: {recall:.2f} | F1: {f1:.2f} | AUC: {auc:.2f}\\n\")\n",
    "\n",
    "        # step if AUC plateaus\n",
    "        scheduler.step(auc)\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "    # load the best model to re-evaluate and save metrics of best model\n",
    "    best_model_path = r\"C:\\Users\\gjkku\\HRNet_best_model.pth\"\n",
    "    if os.path.exists(best_model_path):\n",
    "        point = torch.load(best_model_path, map_location=device)\n",
    "        model.load_state_dict(point)\n",
    "        model.eval()\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"file not found\")\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    # iterate over validation batches (without gradient computation)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # raw logits of the model \n",
    "            outputs = model(images)\n",
    "\n",
    "            # computing probabilities for class 1 (CDR 0.5) using softmax and predictions using argmax\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1] # -> probability of class 1 (CDR 0.5)\n",
    "            preds = torch.argmax(outputs, dim=1) \n",
    "\n",
    "            # storing the predictions, true labels, and probabilities into the lists\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            probabilities.extend(probs.cpu().numpy())\n",
    "                \n",
    "                \n",
    "    # metrics (accuracy, precision, recall, F1-score, AUC)\n",
    "    validation_accuracy = 100 * (np.array(predictions) == np.array(true_labels)).sum() / len(true_labels)\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    auc = roc_auc_score(true_labels, probabilities)\n",
    "        \n",
    "    # SQ1: saving the detection accuracy and other metrics into a CSV file\n",
    "    sq1 = {\n",
    "        \"model\": \"HRNet_w18\",\n",
    "        \"validation accuracy\": round(validation_accuracy * 100, 2),\n",
    "        \"precision\": round(precision, 2),\n",
    "        \"recall\": round(recall, 2),\n",
    "        \"f1\": round(f1, 2),\n",
    "        \"auc\": round(auc, 2)\n",
    "    }\n",
    "\n",
    "    with open(\"SQ1_HRNet.csv\", \"a\", newline='', encoding='utf-8') as f:\n",
    "        w = csv.DictWriter(f, fieldnames=list(sq1.keys()))\n",
    "        if f.tell() == 0:\n",
    "           w.writeheader()\n",
    "        w.writerow(sq1)\n",
    "\n",
    "    # returning true labels and probabilities\n",
    "    return true_labels, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "991d660f-48b7-48fe-8b8c-68d85cb8e722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss: 5.1711 - Train accuracy: 49.07%\n",
      "The best model is saved\n",
      "Validation Accuracy: 50.00%\n",
      "Precision: 0.50 | Recall: 1.00 | F1: 0.67 | AUC: 0.74\n",
      "\n",
      "Epoch 2/50 - Loss: 4.6954 - Train accuracy: 59.72%\n",
      "The best model is saved\n",
      "Validation Accuracy: 74.07%\n",
      "Precision: 0.76 | Recall: 0.70 | F1: 0.73 | AUC: 0.86\n",
      "\n",
      "Epoch 3/50 - Loss: 4.2103 - Train accuracy: 71.30%\n",
      "The best model is saved\n",
      "Validation Accuracy: 81.48%\n",
      "Precision: 0.77 | Recall: 0.89 | F1: 0.83 | AUC: 0.84\n",
      "\n",
      "Epoch 4/50 - Loss: 4.0269 - Train accuracy: 74.07%\n",
      "The best model is saved\n",
      "Validation Accuracy: 85.19%\n",
      "Precision: 0.91 | Recall: 0.78 | F1: 0.84 | AUC: 0.89\n",
      "\n",
      "Epoch 5/50 - Loss: 3.4431 - Train accuracy: 79.17%\n",
      "Validation Accuracy: 75.93%\n",
      "Precision: 0.68 | Recall: 0.96 | F1: 0.80 | AUC: 0.87\n",
      "\n",
      "Epoch 6/50 - Loss: 3.3456 - Train accuracy: 81.94%\n",
      "Validation Accuracy: 85.19%\n",
      "Precision: 0.95 | Recall: 0.74 | F1: 0.83 | AUC: 0.90\n",
      "\n",
      "Epoch 7/50 - Loss: 3.1310 - Train accuracy: 83.80%\n",
      "The best model is saved\n",
      "Validation Accuracy: 87.04%\n",
      "Precision: 0.88 | Recall: 0.85 | F1: 0.87 | AUC: 0.91\n",
      "\n",
      "Epoch 8/50 - Loss: 2.7770 - Train accuracy: 89.35%\n",
      "Validation Accuracy: 87.04%\n",
      "Precision: 0.92 | Recall: 0.81 | F1: 0.86 | AUC: 0.89\n",
      "\n",
      "Epoch 9/50 - Loss: 3.0664 - Train accuracy: 84.72%\n",
      "Validation Accuracy: 81.48%\n",
      "Precision: 0.81 | Recall: 0.81 | F1: 0.81 | AUC: 0.90\n",
      "\n",
      "Epoch 10/50 - Loss: 3.0368 - Train accuracy: 82.41%\n",
      "Validation Accuracy: 70.37%\n",
      "Precision: 0.92 | Recall: 0.44 | F1: 0.60 | AUC: 0.92\n",
      "\n",
      "Noisy training data is now being used\n",
      "Epoch 11/50 - Loss: 2.7881 - Train accuracy: 87.96%\n",
      "Validation Accuracy: 68.52%\n",
      "Precision: 0.92 | Recall: 0.41 | F1: 0.56 | AUC: 0.95\n",
      "\n",
      "Epoch 12/50 - Loss: 2.9420 - Train accuracy: 86.57%\n",
      "Validation Accuracy: 87.04%\n",
      "Precision: 0.81 | Recall: 0.96 | F1: 0.88 | AUC: 0.95\n",
      "\n",
      "Epoch 13/50 - Loss: 2.5812 - Train accuracy: 90.28%\n",
      "Validation Accuracy: 79.63%\n",
      "Precision: 0.71 | Recall: 1.00 | F1: 0.83 | AUC: 0.95\n",
      "\n",
      "Epoch 14/50 - Loss: 2.4035 - Train accuracy: 90.74%\n",
      "Validation Accuracy: 68.52%\n",
      "Precision: 0.92 | Recall: 0.41 | F1: 0.56 | AUC: 0.95\n",
      "\n",
      "Epoch 15/50 - Loss: 2.3970 - Train accuracy: 90.74%\n",
      "Validation Accuracy: 55.56%\n",
      "Precision: 1.00 | Recall: 0.11 | F1: 0.20 | AUC: 0.97\n",
      "\n",
      "Epoch 16/50 - Loss: 2.5163 - Train accuracy: 89.35%\n",
      "Validation Accuracy: 61.11%\n",
      "Precision: 1.00 | Recall: 0.22 | F1: 0.36 | AUC: 0.99\n",
      "\n",
      "Epoch 17/50 - Loss: 2.3490 - Train accuracy: 94.44%\n",
      "The best model is saved\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 1.00 | Recall: 0.85 | F1: 0.92 | AUC: 0.98\n",
      "\n",
      "Epoch 18/50 - Loss: 2.4734 - Train accuracy: 90.28%\n",
      "Validation Accuracy: 88.89%\n",
      "Precision: 0.84 | Recall: 0.96 | F1: 0.90 | AUC: 0.98\n",
      "\n",
      "Epoch 19/50 - Loss: 2.1316 - Train accuracy: 96.30%\n",
      "Validation Accuracy: 55.56%\n",
      "Precision: 1.00 | Recall: 0.11 | F1: 0.20 | AUC: 0.97\n",
      "\n",
      "Epoch 20/50 - Loss: 2.1270 - Train accuracy: 94.44%\n",
      "Validation Accuracy: 75.93%\n",
      "Precision: 1.00 | Recall: 0.52 | F1: 0.68 | AUC: 0.99\n",
      "\n",
      "Epoch 21/50 - Loss: 2.0363 - Train accuracy: 95.83%\n",
      "The best model is saved\n",
      "Validation Accuracy: 94.44%\n",
      "Precision: 0.90 | Recall: 1.00 | F1: 0.95 | AUC: 0.99\n",
      "\n",
      "Epoch 22/50 - Loss: 2.2676 - Train accuracy: 92.59%\n",
      "Validation Accuracy: 75.93%\n",
      "Precision: 1.00 | Recall: 0.52 | F1: 0.68 | AUC: 0.99\n",
      "\n",
      "Epoch 23/50 - Loss: 1.9858 - Train accuracy: 96.76%\n",
      "Validation Accuracy: 75.93%\n",
      "Precision: 1.00 | Recall: 0.52 | F1: 0.68 | AUC: 0.98\n",
      "\n",
      "Epoch 24/50 - Loss: 2.0876 - Train accuracy: 94.91%\n",
      "Validation Accuracy: 77.78%\n",
      "Precision: 1.00 | Recall: 0.56 | F1: 0.71 | AUC: 0.98\n",
      "\n",
      "Epoch 25/50 - Loss: 1.9426 - Train accuracy: 95.83%\n",
      "Validation Accuracy: 87.04%\n",
      "Precision: 0.92 | Recall: 0.81 | F1: 0.86 | AUC: 0.96\n",
      "\n",
      "Epoch 26/50 - Loss: 1.7431 - Train accuracy: 98.61%\n",
      "Validation Accuracy: 94.44%\n",
      "Precision: 0.93 | Recall: 0.96 | F1: 0.95 | AUC: 0.96\n",
      "\n",
      "Epoch 27/50 - Loss: 1.7121 - Train accuracy: 99.54%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.90 | Recall: 0.96 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 28/50 - Loss: 1.7384 - Train accuracy: 97.69%\n",
      "Validation Accuracy: 94.44%\n",
      "Precision: 0.93 | Recall: 0.96 | F1: 0.95 | AUC: 0.97\n",
      "\n",
      "Epoch 29/50 - Loss: 1.8522 - Train accuracy: 97.22%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 30/50 - Loss: 1.6893 - Train accuracy: 98.61%\n",
      "Validation Accuracy: 87.04%\n",
      "Precision: 0.92 | Recall: 0.81 | F1: 0.86 | AUC: 0.97\n",
      "\n",
      "Epoch 31/50 - Loss: 1.6015 - Train accuracy: 99.54%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 32/50 - Loss: 1.6543 - Train accuracy: 98.61%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 33/50 - Loss: 1.5768 - Train accuracy: 99.54%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 34/50 - Loss: 1.5827 - Train accuracy: 99.54%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 35/50 - Loss: 1.6389 - Train accuracy: 98.61%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 36/50 - Loss: 1.7361 - Train accuracy: 97.69%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 37/50 - Loss: 1.7117 - Train accuracy: 98.61%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.98\n",
      "\n",
      "Epoch 38/50 - Loss: 1.5597 - Train accuracy: 99.54%\n",
      "Validation Accuracy: 94.44%\n",
      "Precision: 0.93 | Recall: 0.96 | F1: 0.95 | AUC: 0.98\n",
      "\n",
      "Epoch 39/50 - Loss: 1.8211 - Train accuracy: 97.69%\n",
      "Validation Accuracy: 94.44%\n",
      "Precision: 0.93 | Recall: 0.96 | F1: 0.95 | AUC: 0.97\n",
      "\n",
      "Epoch 40/50 - Loss: 1.6074 - Train accuracy: 98.61%\n",
      "Validation Accuracy: 94.44%\n",
      "Precision: 0.93 | Recall: 0.96 | F1: 0.95 | AUC: 0.97\n",
      "\n",
      "Epoch 41/50 - Loss: 1.5824 - Train accuracy: 99.07%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 42/50 - Loss: 1.6093 - Train accuracy: 99.54%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 43/50 - Loss: 1.6434 - Train accuracy: 98.15%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.98\n",
      "\n",
      "Epoch 44/50 - Loss: 1.6724 - Train accuracy: 97.69%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 45/50 - Loss: 1.6803 - Train accuracy: 97.69%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 46/50 - Loss: 1.6962 - Train accuracy: 98.15%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 47/50 - Loss: 1.6521 - Train accuracy: 98.61%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 48/50 - Loss: 1.6069 - Train accuracy: 99.07%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 49/50 - Loss: 1.6369 - Train accuracy: 98.15%\n",
      "Validation Accuracy: 92.59%\n",
      "Precision: 0.93 | Recall: 0.93 | F1: 0.93 | AUC: 0.97\n",
      "\n",
      "Epoch 50/50 - Loss: 1.7111 - Train accuracy: 97.69%\n",
      "Validation Accuracy: 94.44%\n",
      "Precision: 0.93 | Recall: 0.96 | F1: 0.95 | AUC: 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# keeping track of time (start-time)\n",
    "start_time = time.time()\n",
    "\n",
    "# training model for 50 epochs\n",
    "true_labels, probabilities = train(model, train_loader, validation_loader, loss_function, optimizer, scheduler, device, epochs=50)\n",
    "\n",
    "# keeping track of time (end-time)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb827b94-b0ab-4285-8a66-3a2cfbbdd62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQ2: calculating inference time, memory usage, and overall resource consumption and saving it into a CSV file\n",
    "\n",
    "# load the best model\n",
    "best_model_path = r\"C:\\Users\\gjkku\\HRNet_best_model.pth\"\n",
    "if os.path.exists(best_model_path):\n",
    "    point = torch.load(best_model_path, map_location=device)\n",
    "    model.load_state_dict(point)\n",
    "    model.eval()\n",
    "else:\n",
    "    raise FileNotFoundError(f\"file not found\")        \n",
    "\n",
    "# computing average inference time\n",
    "sample = next(iter(validation_loader))[0][0].unsqueeze(0).to(device)\n",
    "with torch.no_grad():\n",
    "    inf_start = time.time()\n",
    "    for _ in range(100):\n",
    "        _ = model(sample)\n",
    "    inf_end = time.time()\n",
    "    \n",
    "\n",
    "sq2 = {\n",
    "    \"model\": \"HRNet_w18\",\n",
    "    #\"training_time_sec\": round(end_time - start_time, 2), This line is commented, because changes were made after kernel restarted, uncomment after training the model to evaluate training time.\n",
    "    \"model_parameters\": sum(p.numel() for p in model.parameters()),\n",
    "    \"model_size_MB\": round(os.path.getsize('HRNet_best_model.pth') / (1024 * 1024), 2),\n",
    "    \"avg_inference_time_s\": round((inf_end - inf_start)/100, 4)\n",
    "}\n",
    "\n",
    "# saving the metrics for SQ2 into a CSV file\n",
    "with open(\"SQ2_HRNet.csv\", \"a\", newline='') as f:\n",
    "    w = csv.DictWriter(f, fieldnames=sq2.keys())\n",
    "    if f.tell() == 0:\n",
    "       w.writeheader()\n",
    "    w.writerow(sq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fd28b1d-1758-48c0-b10e-c0b2ae8268b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQ3: evaluating robustness by adding noise and blur to validation data\n",
    "\n",
    "best_model_path = r\"C:\\Users\\gjkku\\HRNet_best_model.pth\"\n",
    "if os.path.exists(best_model_path):\n",
    "    point = torch.load(best_model_path, map_location=device)\n",
    "    model.load_state_dict(point)   \n",
    "else:\n",
    "    raise FileNotFoundError(f\"file not found\")\n",
    "    \n",
    "def robustness_test(model, loader, noise_std=0.2, blur=False):\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # lists to store all predictions, true labels, and probabilities for computing metrics of the validation set\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # adding noise\n",
    "            if noise_std > 0:\n",
    "                images = torch.clamp(images + torch.randn_like(images) * noise_std, 0., 1.)\n",
    "            # adding blur\n",
    "            if blur:\n",
    "                images = torch.stack([gaussian_blur(img, kernel_size=3) for img in images])\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            # storing the predictions, true labels, and probabilities into the lists\n",
    "            probabilities.extend(probs.cpu().numpy())\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # returning the metrics\n",
    "    return {\n",
    "        \"acc\": accuracy_score(true_labels, predictions),\n",
    "        \"precision\": precision_score(true_labels, predictions, average='macro', zero_division=0),\n",
    "        \"recall\": recall_score(true_labels, predictions, average='macro', zero_division=0),\n",
    "        \"f1\": f1_score(true_labels, predictions, average='macro', zero_division=0),\n",
    "        \"auc\": roc_auc_score(true_labels, probabilities) if len(set(true_labels)) > 1 else 0.0\n",
    "    }\n",
    "\n",
    "# Run robustness tests\n",
    "test_types = [\n",
    "    # only noise\n",
    "    {\"type\": \"noise\", \"args\": {\"noise_std\": 0.2, \"blur\": False}},\n",
    "    # only blur\n",
    "    {\"type\": \"blur\", \"args\": {\"noise_std\": 0.0, \"blur\": True}},\n",
    "    # both\n",
    "    {\"type\": \"noise+blur\", \"args\": {\"noise_std\": 0.2, \"blur\": True}}\n",
    "]\n",
    "\n",
    "with open(\"SQ3_HRNet.csv\", \"a\", newline='') as f:\n",
    "    w = csv.DictWriter(f, fieldnames=[\"model\", \"type\", \"acc\", \"precision\", \"recall\", \"f1\", \"auc\"])\n",
    "    if f.tell() == 0:\n",
    "        w.writeheader()\n",
    "    for test in test_types:\n",
    "        result = robustness_test(model, validation_loader, **test[\"args\"])\n",
    "        w.writerow({\"model\": \"HRNet_w18\", \"type\": test[\"type\"], **result})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aee939c5-0466-408e-b138-f778a8aaf03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_path = r\"C:\\Users\\gjkku\\HRNet_best_model.pth\"\n",
    "if os.path.exists(best_model_path):\n",
    "    point = torch.load(best_model_path, map_location=device)\n",
    "    model.load_state_dict(point)\n",
    "    model.eval()\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Best model file not found at {best_model_path}\")\n",
    "\n",
    "# lists to store all true labels and predictions\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in validation_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# computation of the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Demented', 'Very Mild Demented'])\n",
    "\n",
    "# confusion matrix plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for HRNet')\n",
    "plt.savefig('HRNet_confusion_matrix.png')  \n",
    "plt.show()  \n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
